{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final-project-MLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxB5q3GhIgbuooatUMHsEE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaulao/BezierCurves/blob/master/projeto-final/final_project_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZkNT8au3Whm"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQHuyigO3cAv",
        "outputId": "a0b71161-6967-4197-9d9f-d2edd7e800b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ClrFjgq3cSE"
      },
      "source": [
        "fraud_training = pd.read_csv('/content/drive/MyDrive/projeto-final/train_out.zip')\n",
        "fraud_test = pd.read_csv('/content/drive/MyDrive/projeto-final/test_out.zip')\n",
        "fraud_validation = pd.read_csv('/content/drive/MyDrive/projeto-final/val_out.zip')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "FOo6YFpT5WGd",
        "outputId": "d53a9d91-f6ba-40b9-e1bc-f5d39bb355e2"
      },
      "source": [
        "fraud_training.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582973</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.147356</td>\n",
              "      <td>0.979968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.163552</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114437</td>\n",
              "      <td>0.850630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.138821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.153840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.069129</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.066814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.816338</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.147356</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.729799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.895111</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372026</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>0.147356</td>\n",
              "      <td>0.084342</td>\n",
              "      <td>0.108189</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.605292</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 244 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6  ...  237  238  239  240  241  242  243\n",
              "0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  1.0  0.0  0.0  0.0  0.0    1\n",
              "1  1.0  0.0  0.0  1.0  0.0  0.0  1.0  ...  0.0  0.0  1.0  0.0  0.0  0.0    1\n",
              "2  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  1.0  1.0  0.0  0.0  0.0  1.0    0\n",
              "3  1.0  1.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  1.0  0.0  1.0  0.0  1.0    1\n",
              "4  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  1.0  1.0  0.0  0.0  0.0  1.0    1\n",
              "\n",
              "[5 rows x 244 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnYzlGbC466T"
      },
      "source": [
        "fraud_training_x = fraud_training.iloc[:, 0:-1].values\n",
        "fraud_training_y = fraud_training.iloc[:, -1].values\n",
        "fraud_test_x = fraud_test.iloc[:,0:-1].values\n",
        "fraud_test_y = fraud_test.iloc[:, -1].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6BB7KVK68W2",
        "outputId": "3327970c-e4f7-4030-8bf4-4fa26b92a3b2"
      },
      "source": [
        "!pip install optuna --quiet"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 302 kB 32.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 55.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRt_I23G4bvW",
        "outputId": "4ba88979-90a1-4991-87f7-5e0c387a56ec"
      },
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.neural_network\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 4)\n",
        "    layers = []\n",
        "    for i in range(n_layers):\n",
        "        layers.append(trial.suggest_int(f'n_units_{i}', 1, 100))\n",
        "\n",
        "    # mnist = sklearn.datasets.fetch_mldata('MNIST original')\n",
        "    x_train, x_test, y_train, y_test = fraud_training_x, fraud_test_x, fraud_training_y, fraud_test_y\n",
        "\n",
        "    clf = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=tuple(layers))\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    return clf.score(x_test, y_test)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 11:02:55,355]\u001b[0m A new study created in memory with name: no-name-093c39e1-749c-4912-bdee-d04127eb3253\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 11:40:09,646]\u001b[0m Trial 0 finished with value: 0.5314388489208633 and parameters: {'n_layers': 4, 'n_units_0': 16, 'n_units_1': 99, 'n_units_2': 87, 'n_units_3': 8}. Best is trial 0 with value: 0.5314388489208633.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 12:10:26,678]\u001b[0m Trial 1 finished with value: 0.4232168550873587 and parameters: {'n_layers': 2, 'n_units_0': 86, 'n_units_1': 31}. Best is trial 0 with value: 0.5314388489208633.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 12:33:07,039]\u001b[0m Trial 2 finished with value: 0.48921891058581707 and parameters: {'n_layers': 3, 'n_units_0': 55, 'n_units_1': 32, 'n_units_2': 94}. Best is trial 0 with value: 0.5314388489208633.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 12:52:41,346]\u001b[0m Trial 3 finished with value: 0.6526104830421378 and parameters: {'n_layers': 3, 'n_units_0': 61, 'n_units_1': 50, 'n_units_2': 33}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 13:02:07,939]\u001b[0m Trial 4 finished with value: 0.5131757451181912 and parameters: {'n_layers': 1, 'n_units_0': 35}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "\u001b[32m[I 2021-08-17 13:03:40,633]\u001b[0m Trial 5 finished with value: 0.6157553956834533 and parameters: {'n_layers': 1, 'n_units_0': 3}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 13:47:33,442]\u001b[0m Trial 6 finished with value: 0.5262384378211716 and parameters: {'n_layers': 4, 'n_units_0': 52, 'n_units_1': 84, 'n_units_2': 45, 'n_units_3': 51}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 14:18:56,860]\u001b[0m Trial 7 finished with value: 0.5498047276464543 and parameters: {'n_layers': 3, 'n_units_0': 62, 'n_units_1': 72, 'n_units_2': 82}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 14:48:44,389]\u001b[0m Trial 8 finished with value: 0.4729188078108941 and parameters: {'n_layers': 2, 'n_units_0': 88, 'n_units_1': 85}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "\u001b[32m[I 2021-08-17 14:52:14,014]\u001b[0m Trial 9 finished with value: 0.4876875642343268 and parameters: {'n_layers': 1, 'n_units_0': 7}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 15:18:11,488]\u001b[0m Trial 10 finished with value: 0.4356526207605344 and parameters: {'n_layers': 3, 'n_units_0': 71, 'n_units_1': 13, 'n_units_2': 2}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 15:36:52,791]\u001b[0m Trial 11 finished with value: 0.5420657759506681 and parameters: {'n_layers': 2, 'n_units_0': 30, 'n_units_1': 58}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 15:43:08,056]\u001b[0m Trial 12 finished with value: 0.42809866392600204 and parameters: {'n_layers': 1, 'n_units_0': 39}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 16:08:44,185]\u001b[0m Trial 13 finished with value: 0.6350154162384378 and parameters: {'n_layers': 3, 'n_units_0': 73, 'n_units_1': 48, 'n_units_2': 29}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 16:57:29,819]\u001b[0m Trial 14 finished with value: 0.6180061664953751 and parameters: {'n_layers': 3, 'n_units_0': 100, 'n_units_1': 48, 'n_units_2': 29}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "\n",
            "\u001b[32m[I 2021-08-17 17:48:24,696]\u001b[0m Trial 15 finished with value: 0.6476670092497431 and parameters: {'n_layers': 4, 'n_units_0': 75, 'n_units_1': 47, 'n_units_2': 24, 'n_units_3': 100}. Best is trial 3 with value: 0.6526104830421378.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}